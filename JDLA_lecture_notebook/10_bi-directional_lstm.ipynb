{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 双方向LSTMによる品詞のタグ付け\n",
    "\n",
    "---\n",
    "## 目的\n",
    "双方向LSTM (Bi-direcitional LSTM) を用いて英単語に対する品詞をタグ付け (POS tagging) を行う．\n",
    "\n",
    "\n",
    "## 対応するチャプター\n",
    "* 10.3: 双方向RNN\n",
    "\n",
    "\n",
    "## データのダウンロード\n",
    "実習に必要なデータをダウンロードします．\n",
    "下記のコードを実行してデータのダウンロードを行ってください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://www.mprg.cs.chubu.ac.jp/~hirakawa/share/tutorial_data/pos-tagging_data.zip\n",
    "!unzip -q -o pos-tagging_data.zip\n",
    "!ls ./pos-tagging_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モジュールのインポート\n",
    "プログラムの実行に必要なモジュールをインポートします．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import chainer\n",
    "from chainer import cuda\n",
    "from chainer import Variable\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.optimizer_hooks import GradientClipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUの確認\n",
    "GPUを使用した計算が可能かどうかを確認します．\n",
    "\n",
    "`GPU avilability: True`と表示されれば，GPUを使用した計算をChainerで行うことが可能です．\n",
    "Falseとなっている場合は，上記の「Google Colaboratoryの設定確認・変更」に記載している手順にしたがって，設定を変更した後に，モジュールのインポートから始めてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GPU availability:', chainer.cuda.available)\n",
    "print('cuDNN availablility:', chainer.cuda.cudnn_enabled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットのダウンロード\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_text_dataset(input_filename):\n",
    "    downloaded = []\n",
    "    with open(input_filename) as f:\n",
    "        for s in f.readlines():\n",
    "            downloaded.append( np.array(list(map(int, s.strip().split(' '))), dtype=np.int32) )\n",
    "    return downloaded\n",
    "\n",
    "train_sentence = download_text_dataset(\"pos-tagging_data/train_sentence.txt\")\n",
    "train_tags = download_text_dataset(\"pos-tagging_data/train_tags.txt\")\n",
    "test_sentence = download_text_dataset(\"pos-tagging_data/test_sentence.txt\")\n",
    "test_tags = download_text_dataset(\"pos-tagging_data/test_tags.txt\")\n",
    "        \n",
    "with open(\"pos-tagging_data/vocab.json\") as f:\n",
    "    vocab = json.load(f)\n",
    "    vocab = {v:k for k, v in vocab.items()}\n",
    "    \n",
    "with open(\"pos-tagging_data/tags.json\") as f:\n",
    "    tags = json.load(f)\n",
    "    tags = {v:k for k, v in tags.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークモデルの定義\n",
    "Bidirectional LSTMを用いて，品詞タグ付けを行うためのネットワークを定義します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_embed(embed, xs):\n",
    "    x_len = [len(x) for x in xs]\n",
    "    x_section = np.cumsum(x_len[:-1])\n",
    "    ex = embed(F.concat(xs, axis=0))\n",
    "    exs = F.split_axis(ex, x_section, 0)\n",
    "    return exs\n",
    "\n",
    "class BiLSTM(chainer.Chain):\n",
    "    \n",
    "    def __init__(self, n_vocab, n_tags, n_layers, n_units):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.embed = L.EmbedID(n_vocab, n_units)\n",
    "            self.bi_lstm = L.NStepBiLSTM(n_layers, n_units, n_units, 0.1)\n",
    "            self.output = L.Linear(2 * n_units, n_tags)\n",
    "    \n",
    "    def forward(self, xs):\n",
    "        xs = [x[::-1] for x in xs]\n",
    "        exs = sequence_embed(self.embed, xs)\n",
    "        \n",
    "        hx, cx, os = self.bi_lstm(None, None, exs)\n",
    "        h = self.output(F.concat(os, axis=0))\n",
    "        return h        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークの作成\n",
    "上のプログラムで定義したネットワークを作成します．\n",
    "ここでは，GPUで学習を行うために，modelをGPUに送るto_gpu関数を利用しています．\n",
    "\n",
    "学習を行う際の最適化方法としてモーメンタムSGD(モーメンタム付き確率的勾配降下法）を利用します．また，学習率を0.01として引数に与えます．そして，最適化方法のsetup関数にネットワークモデルを与えます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vocab = len(vocab)\n",
    "num_tags = len(tags)\n",
    "\n",
    "model = BiLSTM(num_vocab, num_tags, 2, 1024)\n",
    "model.to_gpu()\n",
    "\n",
    "optimizer = chainer.optimizers.MomentumSGD(lr=0.1, momentum=0.9)\n",
    "optimizer.setup(model)\n",
    "optimizer.add_hook(GradientClipping(5.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "\n",
    "学習を実行します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = cuda.cupy\n",
    "\n",
    "# ミニバッチサイズ・エポック数．学習データ数の設定\n",
    "batch_size = 32\n",
    "epoch_num = 100\n",
    "train_data_num = len(train_sentence)\n",
    "num_iter_per_epoch = int(train_data_num / batch_size)\n",
    "\n",
    "start = time()\n",
    "for epoch in range(1, epoch_num + 1):\n",
    "    sum_loss = 0\n",
    "    \n",
    "    perm = np.random.permutation(train_data_num)\n",
    "    \n",
    "    for i in range(0, train_data_num, batch_size):\n",
    "        x = [ Variable(cuda.to_gpu(np.array(train_sentence[ii], dtype=np.int32))) for ii in perm[i:i+batch_size] ]\n",
    "        t = [ Variable(cuda.to_gpu(np.array(train_tags[ii], dtype=np.int32))) for ii in perm[i:i+batch_size] ]\n",
    "\n",
    "        y = model(x)\n",
    "        \n",
    "        loss = F.softmax_cross_entropy(y, F.concat(t, axis=0))\n",
    "        \n",
    "        sum_loss += loss.data\n",
    "        \n",
    "        optimizer.target.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "    \n",
    "    elapsed_time = time() - start\n",
    "    print(\"epoch: {}, mean loss: {}, elapsed_time: {}\".format(epoch,\n",
    "                                                              sum_loss/num_iter_per_epoch,\n",
    "                                                              elapsed_time))\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        model.to_cpu()\n",
    "        chainer.serializers.save_npz(\"bilstm-%03d.npz\" % epoch, model)\n",
    "        model.to_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テスト\n",
    "\n",
    "学習後のネットワークを用いて，翻訳を行います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n",
    "\n",
    "    for i_test in range(2):\n",
    "        x = [Variable(cuda.to_gpu(np.array(test_sentence[i_test], dtype=np.int32)))]\n",
    "        t = np.array(test_tags[i_test], dtype=np.int32)\n",
    "\n",
    "        y = model(x)\n",
    "        pred = F.argmax(y, axis=1)\n",
    "        \n",
    "        input_sentence = [vocab[i] for i in cuda.to_cpu(x[0].data)]\n",
    "        pred_tags = [tags[i] for i in cuda.to_cpu(pred.data)]\n",
    "        true_tags = [tags[i] for i in t]\n",
    "\n",
    "        print(\"input sentence:\", \" \".join(input_sentence))\n",
    "        print(\"predicted POS :\", \" \".join(pred_tags))\n",
    "        print(\"true POS      :\", \" \".join(true_tags) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テスト（学習済みモデル）\n",
    "\n",
    "学習には時間を要するため，下記のコードでは学習済みのモデルを読み込んで，学習後のネットワークでの翻訳結果を確認します．\n",
    "保存したモデルパラメータを読み込んで，テストデータの翻訳を行います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vocab = len(vocab)\n",
    "num_tags = len(tags)\n",
    "pretrained_model = BiLSTM(num_vocab, num_tags, 2, 1024)\n",
    "\n",
    "chainer.serializers.load_npz(\"pos-tagging_data/bilstm.npz\", pretrained_model)\n",
    "pretrained_model.to_gpu()\n",
    "\n",
    "\n",
    "with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n",
    "\n",
    "    for i_test in range(2):\n",
    "        x = [Variable(cuda.to_gpu(np.array(test_sentence[i_test], dtype=np.int32)))]\n",
    "        t = np.array(test_tags[i_test], dtype=np.int32)\n",
    "\n",
    "        y = pretrained_model(x)\n",
    "        pred = F.argmax(y, axis=1)\n",
    "        \n",
    "        input_sentence = [vocab[i] for i in cuda.to_cpu(x[0].data)]\n",
    "        pred_tags = [tags[i] for i in cuda.to_cpu(pred.data)]\n",
    "        true_tags = [tags[i] for i in t]\n",
    "\n",
    "        print(\"input sentence:\", \" \".join(input_sentence))\n",
    "        print(\"predicted POS :\", \" \".join(pred_tags))\n",
    "        print(\"true POS      :\", \" \".join(true_tags) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
