{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"08_SemanticSegmentation.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"FCWsTzQXtZI7","colab_type":"text"},"cell_type":"markdown","source":["# Chainerによるセマンティックセグメンテーション\n","\n","##本チュートリアルではchainerを利用してセマンティックセグメンテーションの実装を確認，学習および評価を行います．　環境としてはGoogle が提供する Google Colaboratory上でおこないます． GPU上で処理を行うため，colaboratoryの[ランタイム]->[ランタイムのタイプを変更]からハードウェアアクセラレータをGPUにしてください．"]},{"metadata":{"id":"30MMRPy8tzWt","colab_type":"text"},"cell_type":"markdown","source":["Goolge Colaboratory上にChainerとChainerCVをインストールします．"]},{"metadata":{"id":"IkksRbnlh8hV","colab_type":"code","colab":{}},"cell_type":"code","source":["!curl https://colab.chainer.org/install | sh -\n","!pip install 'chainercv'\n","\n","!pip install tqdm"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gUidNaiKUP2M","colab_type":"text"},"cell_type":"markdown","source":["学習したモデルをgoogle driveに保存するための処理を行います．途中でgoogle driveにアクセスするためのキー入力が求められます．その際，表示されたURLをクリックし，アクセスの許可をするとキーが表示されます．そのキーをコピーし，キー入力のエリアに貼り付けしてください．キー入力は２回求められます．それぞれ別々のキーなので，それぞれのURLをクリックして，同様の手順で行ってください．"]},{"metadata":{"id":"jWllehE-snPu","colab_type":"text"},"cell_type":"markdown","source":["まずはSegNetの推論処理を実行します．セグメンテーションに必要なモジュールや関数をインポートします．"]},{"metadata":{"id":"7qolZekhukSL","colab_type":"code","colab":{}},"cell_type":"code","source":["from collections import defaultdict\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import chainer\n","\n","from chainercv.datasets import camvid_label_colors\n","from chainercv.datasets import camvid_label_names\n","from chainercv.datasets import CamVidDataset\n","from chainercv.links import SegNetBasic\n","from chainercv import utils\n","from chainercv.visualizations import vis_image\n","from chainercv.visualizations import vis_semantic_segmentation\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vAg1M7RauUk_","colab_type":"text"},"cell_type":"markdown","source":["ここではCamVidというデータセットで学習されたSegNetBasicをモデルとして利用します．"]},{"metadata":{"id":"UX3PKRO3Ptr4","colab_type":"code","colab":{}},"cell_type":"code","source":["chainer.config.train = False\n","premodel_name =\"camvid\"\n","model = SegNetBasic(n_class=len(camvid_label_names),pretrained_model=premodel_name)\n","model.to_gpu()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kiO7jjLsVb7X","colab_type":"text"},"cell_type":"markdown","source":["テストに用いる画像ファイル名を指定します．\n","左側の矢印メニューをクリックし，ファイルを選択します．\n","アップロードより，検出処理させたい画像をアップロードします．\n","そのファイル名をimage_nameに代入します．\n","img_nameの画像を読み込み，セグメンテーション処理を行います．"]},{"metadata":{"id":"AZs4ozP1QmCD","colab_type":"code","colab":{}},"cell_type":"code","source":["img_name=\"28554775_10216169965424085_897703047_o.jpg\"\n","img = utils.read_image(img_name, color=True)\n","labels = model.predict([img])\n","label = labels[0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Tlq6kItTVoK0","colab_type":"text"},"cell_type":"markdown","source":["元画像とセグメンテーション結果画像を表示します． chainerCVでは，vis_semantic_segmentationという画像を表示するためのクラスが用意されています．これは，セグメンテーション処理結果をもとにクラスごとに色分けした画像を作成してくれます．"]},{"metadata":{"id":"SVFgpyrSPvsJ","colab_type":"code","colab":{}},"cell_type":"code","source":["def clearLabel(_ax):\n","  _ax.tick_params(labelbottom=\"off\",bottom=\"off\")\n","  _ax.tick_params(labelleft=\"off\",left=\"off\")\n","  _ax.set_xticklabels([]) \n","  _ax.axis('off')\n","  return _ax\n","\n","fig = plt.figure()\n","ax1 = fig.add_subplot(1, 2, 1)\n","clearLabel(ax1)\n","vis_image(img, ax=ax1)\n","ax2 = fig.add_subplot(1, 2, 2)\n","clearLabel(ax2)\n","vis_semantic_segmentation( None, label, camvid_label_names, camvid_label_colors, ax=ax2)\n","plt.show()\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6QFiv6_tugth","colab_type":"text"},"cell_type":"markdown","source":["次に，セグメンテーションの学習を行います．学習に必要なパッケージ類をインポートします\n","\n"]},{"metadata":{"id":"T1Ah5r_Yug2V","colab_type":"code","colab":{}},"cell_type":"code","source":["import chainer\n","import numpy as np\n","from functools import partial\n","import time\n","\n","\n","from chainer.datasets import TransformDataset\n","from chainer import optimizers, cuda, Variable\n","\n","from chainercv.datasets import camvid_label_names\n","from chainercv.datasets import CamVidDataset\n","from chainercv.links import PixelwiseSoftmaxClassifier\n","from chainercv.links import SegNetBasic\n","\n","chainer.config.train = True"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vXY14uy_Roqm","colab_type":"code","colab":{}},"cell_type":"code","source":["!cp -r \"drive/Colab Notebooks/DL_Tutorial/camvid\" ./"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YJPdMRMfR4e-","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"B4OSe7K1vA74","colab_type":"text"},"cell_type":"markdown","source":["data augmentationを行う関数transformを用意します．ここでは，画像の左右反転をランダムに行うようにします．"]},{"metadata":{"id":"scqvWP2GvBdG","colab_type":"code","colab":{}},"cell_type":"code","source":["def transform(in_data):\n","    img, label = in_data\n","    if np.random.rand() > 0.5:\n","        img = img[:, :, ::-1]\n","        label = label[:, ::-1]\n","    return img, label"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BK8AWdq6vHhw","colab_type":"text"},"cell_type":"markdown","source":["学習と評価にはCamVidというデータセットを用います．　chainerCVではCamVidのデータセットをダウンロードし，学習と評価のデータセットに分けることができます．"]},{"metadata":{"id":"2E340-AavYbo","colab_type":"code","colab":{}},"cell_type":"code","source":["train_dataset = CamVidDataset(data_dir=\"camvid\", split='train')\n","val_dataset    = CamVidDataset(data_dir=\"camvid\", split='val')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rj8HUTURvYSs","colab_type":"text"},"cell_type":"markdown","source":["学習データにdata augmentationを施しながらデータを取得するように高階関数partialを用いて，TransformDatasetを用意します．"]},{"metadata":{"id":"WHFGUWL_85TJ","colab_type":"code","colab":{}},"cell_type":"code","source":["train_transform = partial(transform)\n","valid_transform = partial(transform)\n","\n","train_dataset = TransformDataset(train_dataset, train_transform)\n","val_dataset    = TransformDataset(val_dataset, valid_transform)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2i4WZfQYXjno","colab_type":"text"},"cell_type":"markdown","source":["CamVidデータセットには木や歩行者，道路など11クラスあり，各クラスの出現確率はバラバラです．そのため，学習時に出現確率が高いクラスに偏った学習がされてしまいます．そこで，クラスの出現確率を考慮した重みを用意します．これは，出現確率が低いほど大きな重みとし，その重みを誤差逆伝播時に利用します．これにより，出現確率の低いクラスの誤差をより大きく更新に反映させることができます．"]},{"metadata":{"id":"rrWAHNszGMWi","colab_type":"code","colab":{}},"cell_type":"code","source":["n_class = 11\n","dataset = CamVidDataset(data_dir=\"camvid\",split='train')\n","\n","n_cls_pixels = np.zeros((n_class,))\n","n_img_pixels = np.zeros((n_class,))\n","\n","for img, label in dataset:\n","    for cls_i in np.unique(label):\n","        if cls_i == -1:\n","            continue\n","        n_cls_pixels[cls_i] += np.sum(label == cls_i)\n","        n_img_pixels[cls_i] += label.size\n","freq = n_cls_pixels / n_img_pixels\n","median_freq = np.median(freq)\n","class_weight = median_freq / freq"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZSpQpgzl2AFG","colab_type":"text"},"cell_type":"markdown","source":["ネットワーク構造を定義します．SegNetの構造はSegNetBasicとして用意されています．また，セマンティックセグメンテーションの場合は各画素に対して識別を行うので，PixelwiseSoftmaxClassifierを利用します．"]},{"metadata":{"id":"3ItMpSpnwmHU","colab_type":"code","colab":{}},"cell_type":"code","source":["xp = cuda.cupy\n","model = SegNetBasic(n_class=len(camvid_label_names))\n","model = PixelwiseSoftmaxClassifier( model, class_weight = class_weight)\n","model.to_gpu()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3kRhCuuc2Ttx","colab_type":"text"},"cell_type":"markdown","source":["最適化手法にはモーメンタム付きのSGDを利用します．"]},{"metadata":{"id":"g4hAwTlKuzVT","colab_type":"code","colab":{}},"cell_type":"code","source":["optimizer = optimizers.MomentumSGD(lr=0.1, momentum=0.9)\n","optimizer.setup(model)\n","optimizer.add_hook(chainer.optimizer_hooks.WeightDecay(rate=0.0005))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HbvrgkC22Za4","colab_type":"text"},"cell_type":"markdown","source":["学習を行います．"]},{"metadata":{"id":"QLH0M2Qg9zit","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 12\n","epoch_num = 100\n","    \n","start = time.time()\n","for epoch in range(epoch_num):\n","    dataset_x = []\n","    dataset_label =[]\n","    train_data_num = len(train_dataset)\n","    iter_one_epoch = int(train_data_num/batch_size)\n","    sum_loss = 0\n","#    if (epoch+1) % 25 == 0 :\n","#        optimizer.lr *= 0.1\n","    perm = np.random.permutation(train_data_num)\n","    for i in range(len(train_dataset)):\n","        train_sample = train_dataset.get_example(perm[i])\n","        dataset_x.append(train_sample[0])\n","        dataset_label.append(train_sample[1])\n","\n","        if len(dataset_x)==batch_size:\n","            train_x = xp.asarray(dataset_x, xp.float32)\n","            train_label = xp.asarray(dataset_label, xp.int32)\n","            dataset_x = []\n","            dataset_label =[]         \n","\n","            x = Variable(cuda.to_gpu(train_x))\n","            glabel = Variable(cuda.to_gpu(train_label))\n","            loss = model(x, glabel)        \n","            model.zerograds()\n","            loss.backward()\n","            optimizer.update()\n","            sum_loss += loss.data\n","    elapsed_time = time.time() - start            \n","    print(\"epoch: {}, mean loss: {}, proc. time {}\".format(epoch+1, sum_loss*batch_size/train_data_num, elapsed_time))\n","\n","    if (epoch+1) %5 == 0:\n","        chainer.serializers.save_hdf5('drive/Colab Notebooks/DL_Tutorial/SemSeg_Camvid_{}.npz'.format(epoch+1), model, compression=6)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0WGIyKocdAuz","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls \"drive/Colab Notebooks/DL_Tutorial/\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"IXb7pEXvFhji","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"nNk9GI-WbAOX","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls \"drive/Colab Notebooks/DL_Tutorial/SemSeg_Camvid_100.npz\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"pY4TAs60FiRF","colab_type":"code","colab":{}},"cell_type":"code","source":["chainer.config.train = False\n","premodel_name =\"camvid\"\n","test_model = SegNetBasic(n_class=len(camvid_label_names))\n","test_model = PixelwiseSoftmaxClassifier( test_model, class_weight = class_weight)\n","chainer.serializers.load_hdf5(\"drive/Colab Notebooks/DL_Tutorial/SemSeg_Camvid_5.npz\", test_model)\n","test_model.to_gpu()\n","\n","img_name=\"drive/Colab Notebooks/DL_Tutorial/0006R0_f02040.png\"\n","img = utils.read_image(img_name, color=True)\n","x = Variable(cuda.to_gpu(xp.asarray(img, xp.float32) ))\n","\n","y = test_model.predictor([x])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cFO1uxESFiof","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import os\n","import time\n","\n","import chainer\n","from chainercv.links import SegNetBasic\n","from chainercv.datasets import CamVidDataset\n","from chainercv.datasets import camvid_label_names\n","from chainercv.links import PixelwiseSoftmaxClassifier\n","\n","from chainercv import utils\n","from chainer import optimizers, cuda, Variable"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NPH5N-eUvBvF","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","data_dir=\"drive/Colab Notebooks/DL_Tutorial/camvid\"\n","split=\"train\"\n","img_list_path = os.path.join(data_dir, '{}.txt'.format(split))\n","train_dataset = [  [os.path.join(data_dir, fn.replace('/SegNet/CamVid/', ''))   for fn in line.split()] for line in open(img_list_path)]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ct3ea3Wj3OPT","colab_type":"code","colab":{}},"cell_type":"code","source":["def transform(in_data):\n","    img, label = in_data\n","    if np.random.rand() > 0.5:\n","        img = img[:, :, ::-1]\n","        label = label[:, ::-1]\n","    return img, label"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yhgiHnQtF3tS","colab_type":"code","colab":{}},"cell_type":"code","source":["n_class = 11\n","dataset = CamVidDataset(data_dir=\"drive/Colab Notebooks/DL_Tutorial/camvid\",split='train')\n","\n","n_cls_pixels = np.zeros((n_class,))\n","n_img_pixels = np.zeros((n_class,))\n","\n","for img, label in dataset:\n","    for cls_i in np.unique(label):\n","        if cls_i == -1:\n","            continue\n","        n_cls_pixels[cls_i] += np.sum(label == cls_i)\n","        n_img_pixels[cls_i] += label.size\n","freq = n_cls_pixels / n_img_pixels\n","median_freq = np.median(freq)\n","class_weight = median_freq / freq"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5kfG56-P5UPu","colab_type":"code","colab":{}},"cell_type":"code","source":["xp = cuda.cupy\n","model = SegNetBasic(n_class=len(camvid_label_names))\n","model = PixelwiseSoftmaxClassifier( model, class_weight = class_weight)\n","model.to_gpu()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Cpz_xCUdGWG-","colab_type":"code","colab":{}},"cell_type":"code","source":["optimizer = optimizers.MomentumSGD(lr=0.1, momentum=0.9)\n","optimizer.setup(model)\n","optimizer.add_hook(chainer.optimizer_hooks.WeightDecay(rate=0.0005))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XvdNzgllxPJu","colab_type":"code","colab":{}},"cell_type":"code","source":["from chainercv.utils import read_image\n","\n","batch_size = 12\n","epoch_num = 100\n","    \n","for epoch in range(epoch_num):\n","    start = time.time()\n","    sum_loss = 0\n","    train_data_num = len(train_dataset)\n","    iter_one_epoch = int(train_data_num/batch_size)\n","    dataset_x = []\n","    dataset_label =[]\n","    perm = np.random.permutation(train_data_num)\n","\n","    for i in range(len(train_dataset)):\n","        data_path , label_path = train_dataset[perm[i]]\n","        img = read_image(data_path, color=True)\n","        label = read_image(label_path, dtype=np.int32, color=False)[0]\n","        label[label == 11] = -1\n","        img, label = transform([img, label])\n","\n","        dataset_x.append(img)\n","        dataset_label.append(label)\n","\n","        if (len(dataset_x) == batch_size):\n","            train_x = xp.asarray(dataset_x, xp.float32)\n","            train_label = xp.asarray(dataset_label, xp.int32)\n","            dataset_x = []\n","            dataset_label =[]         \n","            \n","            x = Variable(cuda.to_gpu(train_x))\n","            glabel = Variable(cuda.to_gpu(train_label))\n","            loss = model(x, glabel)        \n","            model.zerograds()\n","            loss.backward()\n","            optimizer.update()\n","            sum_loss += loss.data\n","    elapsed_time = time.time() - start            \n","    print(\"epoch: {}, mean loss: {}, proc. time {}\".format(epoch+1, sum_loss*batch_size/train_data_num, elapsed_time))\n","\n","\n","    \n","\n","\n"],"execution_count":0,"outputs":[]}]}